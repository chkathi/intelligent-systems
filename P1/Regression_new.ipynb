{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 00:05:10.455516: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professor's Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Business and Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data from JSON to Pandas\n",
    "reviews = pd.read_json('yelp_academic_dataset_review.json', lines=True, nrows=1000000)\n",
    "\n",
    "business = pd.read_json('yelp_academic_dataset_business.json', lines=True, nrows=1000000)\n",
    "\n",
    "# Rename to distinguish star ratings after join\n",
    "reviews = reviews.rename(columns={'stars': 'review_rating'})\n",
    "business = business.rename(columns={'stars': 'business_rating'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (59699, 15)\n",
      "After (59699, 15)\n"
     ]
    }
   ],
   "source": [
    "# Add Location Column\n",
    "business['location'] = business['city'] + \", \" + business['state']\n",
    "\n",
    "# Filter businesses out (review_count < 20 and null business_id & review_count)\n",
    "business =  business[business.review_count > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review_id', 'user_id', 'business_id', 'review_rating', 'useful',\n",
      "       'funny', 'cool', 'text', 'date', 'name', 'address', 'city', 'state',\n",
      "       'postal_code', 'latitude', 'longitude', 'business_rating',\n",
      "       'review_count', 'is_open', 'attributes', 'categories', 'hours',\n",
      "       'location'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>business_rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>...</td>\n",
       "      <td>19454</td>\n",
       "      <td>40.210196</td>\n",
       "      <td>-75.223639</td>\n",
       "      <td>3.0</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NoiseLevel': 'u'average'', 'HasTV': 'False',...</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch, Food, Juice B...</td>\n",
       "      <td>{'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...</td>\n",
       "      <td>North Wales, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "      <td>Body Cycle Spinning Studio</td>\n",
       "      <td>...</td>\n",
       "      <td>19119</td>\n",
       "      <td>39.952103</td>\n",
       "      <td>-75.172753</td>\n",
       "      <td>5.0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'GoodFo...</td>\n",
       "      <td>Active Life, Cycling Classes, Trainers, Gyms, ...</td>\n",
       "      <td>{'Monday': '6:30-20:30', 'Tuesday': '6:30-20:3...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "      <td>Kettle Restaurant</td>\n",
       "      <td>...</td>\n",
       "      <td>85713</td>\n",
       "      <td>32.207233</td>\n",
       "      <td>-110.980864</td>\n",
       "      <td>3.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsReservations': 'True', 'BusinessP...</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>Zaika</td>\n",
       "      <td>...</td>\n",
       "      <td>19114</td>\n",
       "      <td>40.079848</td>\n",
       "      <td>-75.025080</td>\n",
       "      <td>4.0</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Caters': 'True', 'Ambience': '{'romantic': F...</td>\n",
       "      <td>Halal, Pakistani, Restaurants, Indian</td>\n",
       "      <td>{'Tuesday': '11:0-21:0', 'Wednesday': '11:0-21...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>Melt</td>\n",
       "      <td>...</td>\n",
       "      <td>70119</td>\n",
       "      <td>29.962102</td>\n",
       "      <td>-90.087958</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BusinessParking': '{'garage': False, 'street...</td>\n",
       "      <td>Sandwiches, Beer, Wine &amp; Spirits, Bars, Food, ...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Friday': '11:0-17:0', '...</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   review_rating  useful  funny  cool  \\\n",
       "0              3       0      0     0   \n",
       "1              5       1      0     1   \n",
       "2              3       0      0     0   \n",
       "3              5       1      0     1   \n",
       "4              4       1      0     1   \n",
       "\n",
       "                                                text                date  \\\n",
       "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11   \n",
       "1  I've taken a lot of spin classes over the year... 2012-01-03 15:28:18   \n",
       "2  Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30   \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03   \n",
       "4  Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15   \n",
       "\n",
       "                           name  ... postal_code   latitude   longitude  \\\n",
       "0  Turning Point of North Wales  ...       19454  40.210196  -75.223639   \n",
       "1    Body Cycle Spinning Studio  ...       19119  39.952103  -75.172753   \n",
       "2             Kettle Restaurant  ...       85713  32.207233 -110.980864   \n",
       "3                         Zaika  ...       19114  40.079848  -75.025080   \n",
       "4                          Melt  ...       70119  29.962102  -90.087958   \n",
       "\n",
       "  business_rating  review_count  is_open  \\\n",
       "0             3.0           169        1   \n",
       "1             5.0           144        0   \n",
       "2             3.5            47        1   \n",
       "3             4.0           181        1   \n",
       "4             4.0            32        0   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  {'NoiseLevel': 'u'average'', 'HasTV': 'False',...   \n",
       "1  {'BusinessAcceptsCreditCards': 'True', 'GoodFo...   \n",
       "2  {'RestaurantsReservations': 'True', 'BusinessP...   \n",
       "3  {'Caters': 'True', 'Ambience': '{'romantic': F...   \n",
       "4  {'BusinessParking': '{'garage': False, 'street...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Restaurants, Breakfast & Brunch, Food, Juice B...   \n",
       "1  Active Life, Cycling Classes, Trainers, Gyms, ...   \n",
       "2                    Restaurants, Breakfast & Brunch   \n",
       "3              Halal, Pakistani, Restaurants, Indian   \n",
       "4  Sandwiches, Beer, Wine & Spirits, Bars, Food, ...   \n",
       "\n",
       "                                               hours          location  \n",
       "0  {'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...   North Wales, PA  \n",
       "1  {'Monday': '6:30-20:30', 'Tuesday': '6:30-20:3...  Philadelphia, PA  \n",
       "2                                               None        Tucson, AZ  \n",
       "3  {'Tuesday': '11:0-21:0', 'Wednesday': '11:0-21...  Philadelphia, PA  \n",
       "4  {'Monday': '0:0-0:0', 'Friday': '11:0-17:0', '...   New Orleans, LA  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the business and reviews together \n",
    "all_reviews = pd.merge(reviews,business, on='business_id') \n",
    "\n",
    "print(all_reviews.columns)\n",
    "all_reviews.head()\n",
    "# all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the business's reviews into one text\n",
    "business_reviews = all_reviews.groupby('business_id')['text'].sum()\n",
    "\n",
    "# # Create a dataframe with the business and its all its cooresponding reviews\n",
    "df_business_reviews = pd.DataFrame({\n",
    "  'business_id' : business_reviews.index, \n",
    "  'all_reviews' : business_reviews.values,\n",
    "})\n",
    "\n",
    "df_business_reviews = pd.merge(df_business_reviews, business[['business_id', 'location', 'review_count', 'business_rating']], on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abington Township, PA</th>\n",
       "      <th>Abington, PA</th>\n",
       "      <th>Affton, MO</th>\n",
       "      <th>Aldan, PA</th>\n",
       "      <th>Alton, IL</th>\n",
       "      <th>Ambler, PA</th>\n",
       "      <th>Antioch, TN</th>\n",
       "      <th>Apollo Beach, FL</th>\n",
       "      <th>Arabi, LA</th>\n",
       "      <th>Ardmore, PA</th>\n",
       "      <th>...</th>\n",
       "      <th>Yeadon, PA</th>\n",
       "      <th>Zephyrhills, FL</th>\n",
       "      <th>Zionsville, IN</th>\n",
       "      <th>boise, ID</th>\n",
       "      <th>clearwater, FL</th>\n",
       "      <th>wilmington, DE</th>\n",
       "      <th>business_id</th>\n",
       "      <th>all_reviews</th>\n",
       "      <th>review_count</th>\n",
       "      <th>business_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>--ZVrH2X2QXBFdCilbirsw</td>\n",
       "      <td>This place is sadly perm closed. I was hoping ...</td>\n",
       "      <td>-0.407142</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>--sXnWH9Xm6_NvIjyuA99w</td>\n",
       "      <td>Ich war das erste mal in Philadelphia und ich ...</td>\n",
       "      <td>-0.424863</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-02xFuruu85XmDn2xiynJw</td>\n",
       "      <td>Dr. Curtis Dechant has an excellent chair-side...</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-06OYKiIzxsdymBMDAKZug</td>\n",
       "      <td>Had catalytic converters replaced on our Subur...</td>\n",
       "      <td>-0.395328</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-06ngMH_Ejkm_6HQBYxB7g</td>\n",
       "      <td>I have an old main line that really should be ...</td>\n",
       "      <td>-0.448491</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Abington Township, PA  Abington, PA  Affton, MO  Aldan, PA  Alton, IL  \\\n",
       "0                  False         False       False      False      False   \n",
       "1                  False         False       False      False      False   \n",
       "2                  False         False       False      False      False   \n",
       "3                  False         False       False      False      False   \n",
       "4                  False         False       False      False      False   \n",
       "\n",
       "   Ambler, PA  Antioch, TN  Apollo Beach, FL  Arabi, LA  Ardmore, PA  ...  \\\n",
       "0       False        False             False      False         True  ...   \n",
       "1       False        False             False      False        False  ...   \n",
       "2       False        False             False      False        False  ...   \n",
       "3       False        False             False      False        False  ...   \n",
       "4       False        False             False      False        False  ...   \n",
       "\n",
       "   Yeadon, PA  Zephyrhills, FL  Zionsville, IN  boise, ID  clearwater, FL  \\\n",
       "0       False            False           False      False           False   \n",
       "1       False            False           False      False           False   \n",
       "2       False            False           False      False           False   \n",
       "3       False            False           False      False           False   \n",
       "4       False            False           False      False           False   \n",
       "\n",
       "   wilmington, DE             business_id  \\\n",
       "0           False  --ZVrH2X2QXBFdCilbirsw   \n",
       "1           False  --sXnWH9Xm6_NvIjyuA99w   \n",
       "2           False  -02xFuruu85XmDn2xiynJw   \n",
       "3           False  -06OYKiIzxsdymBMDAKZug   \n",
       "4           False  -06ngMH_Ejkm_6HQBYxB7g   \n",
       "\n",
       "                                         all_reviews  review_count  \\\n",
       "0  This place is sadly perm closed. I was hoping ...     -0.407142   \n",
       "1  Ich war das erste mal in Philadelphia und ich ...     -0.424863   \n",
       "2  Dr. Curtis Dechant has an excellent chair-side...      0.047699   \n",
       "3  Had catalytic converters replaced on our Subur...     -0.395328   \n",
       "4  I have an old main line that really should be ...     -0.448491   \n",
       "\n",
       "   business_rating  \n",
       "0              4.5  \n",
       "1              4.0  \n",
       "2              4.5  \n",
       "3              4.5  \n",
       "4              4.0  \n",
       "\n",
       "[5 rows x 550 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding for location\n",
    "df_encoded = pd.get_dummies(df_business_reviews['location'])\n",
    "df_business_reviews = pd.concat([df_encoded, df_business_reviews], axis=1)\n",
    "\n",
    "# Drop location column now that one)\n",
    "df_business_reviews.drop(['location'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Replace nulls with mean and normalize review count for the business\n",
    "missing_median(df_business_reviews, 'review_count')\n",
    "encode_numeric_zscore(df_business_reviews, 'review_count')\n",
    "\n",
    "df_business_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_business_reviews['all_reviews']\n",
    "text.head()\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english',max_features=1000,min_df=1)\n",
    "# Fit and transform the aggregated reviews into a TF-IDF matrix\n",
    "tfidf_wm = vectorizer.fit_transform(text)\n",
    "\n",
    "# Retrieve the feature names (i.e., the vocabulary)\n",
    "tfidf_tokens = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame from the TF-IDF matrix for easier viewing\n",
    "df_tfidfvect = pd.DataFrame(data=tfidf_wm.toarray(), columns=tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00pm</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10am</th>\n",
       "      <th>10pm</th>\n",
       "      <th>11</th>\n",
       "      <th>11am</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00  000  00pm        10       100  1000  10am  10pm   11  11am  ...  \\\n",
       "0  0.010745  0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  0.0   0.0  ...   \n",
       "1  0.000000  0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  0.0   0.0  ...   \n",
       "2  0.000000  0.0   0.0  0.001932  0.012100   0.0   0.0   0.0  0.0   0.0  ...   \n",
       "3  0.072024  0.0   0.0  0.000000  0.037985   0.0   0.0   0.0  0.0   0.0  ...   \n",
       "4  0.000000  0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  0.0   0.0  ...   \n",
       "\n",
       "   york     young  younger  yuck       yum  yummy  zero  zone  zoo  zucchini  \n",
       "0   0.0  0.000000      0.0   0.0  0.026259    0.0   0.0   0.0  0.0       0.0  \n",
       "1   0.0  0.000000      0.0   0.0  0.000000    0.0   0.0   0.0  0.0       0.0  \n",
       "2   0.0  0.002882      0.0   0.0  0.000000    0.0   0.0   0.0  0.0       0.0  \n",
       "3   0.0  0.000000      0.0   0.0  0.000000    0.0   0.0   0.0  0.0       0.0  \n",
       "4   0.0  0.000000      0.0   0.0  0.000000    0.0   0.0   0.0  0.0       0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidfvect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9216, 1000) (9216,) (2304, 1000) (2304,)\n"
     ]
    }
   ],
   "source": [
    "# Combine x and y into a single DataFrame\n",
    "df_combined = pd.concat([df_tfidfvect, df_business_reviews['business_rating']], axis=1)\n",
    "\n",
    "# Use the to_xy function to convert the DataFrame to x and y arrays\n",
    "x, y = to_xy(df_combined, 'business_rating')\n",
    "\n",
    "# Now split the transformed data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Check the shape of the resulting arrays\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tester(hidden_layers=[], activation_function='relu', optimizer='adam', batch_size=32, learning_rate=0.01, dropout_rate=0.0): \n",
    "  # Initialize Optimizers\n",
    "  adam = optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "  sgd = optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)  \n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "  for i in hidden_layers: \n",
    "    model.add(Dense(i, activation=activation_function))\n",
    "    if dropout_rate > 0 and i % 2 == 1:\n",
    "      model.add(Dropout(dropout_rate))\n",
    "\n",
    "  model.add(Dense(1))\n",
    "\n",
    "  if optimizer == 'adam': \n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "  else: \n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "  # Initialize ModelCheckpoint and EarlyStopping\n",
    "  monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=1, mode='auto')\n",
    "  checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights1.keras\", verbose=0, save_best_only=True)\n",
    "\n",
    "  model.fit(\n",
    "    x_train,y_train, validation_data=(x_test,y_test), \n",
    "    batch_size=batch_size, callbacks=[monitor, checkpointer],\n",
    "    verbose=2,epochs=100\n",
    "  )\n",
    "\n",
    "  model.load_weights('dnn/best_weights1.keras') # load weights from best model\n",
    "\n",
    "  # Predict and measure RMSE\n",
    "  pred = model.predict(x_test)\n",
    "  score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "\n",
    "  return (score, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\n",
    "    # 3 Hidden Layers\n",
    "    {'hidden_layers': [256, 128, 64], 'activation_function': 'relu', 'optimizer': 'adam', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32}, \n",
    "    {'hidden_layers': [256, 128, 64], 'activation_function': 'sigmoid', 'optimizer': 'adam', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32}, \n",
    "    {'hidden_layers': [256, 128, 64], 'activation_function': 'tanh', 'optimizer': 'adam', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32}, \n",
    "    {'hidden_layers': [256, 128, 64], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32}, \n",
    "    {'hidden_layers': [256, 128, 64], 'activation_function': 'sigmoid', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32}, \n",
    "    {'hidden_layers': [256, 128, 64], 'activation_function': 'tanh', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32}, \n",
    "\n",
    "    # 4 Hidden Layers\n",
    "    {'hidden_layers': [512, 256, 128, 64], 'activation_function': 'relu', 'optimizer': 'adam', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.001, 'batch_size': 32}, \n",
    "    {'hidden_layers': [512, 256, 128, 64], 'activation_function': 'sigmoid', 'optimizer': 'adam', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.001, 'batch_size': 32}, \n",
    "    {'hidden_layers': [512, 256, 128, 64], 'activation_function': 'tanh', 'optimizer': 'adam', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.001, 'batch_size': 32}, \n",
    "    {'hidden_layers': [512, 256, 128, 64], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.001, 'batch_size': 32}, \n",
    "    {'hidden_layers': [512, 256, 128, 64], 'activation_function': 'sigmoid', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.001, 'batch_size': 32}, \n",
    "    {'hidden_layers': [512, 256, 128, 64], 'activation_function': 'tanh', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.001, 'batch_size': 32}, \n",
    "\n",
    "    # Variety of models with relu and sgd\n",
    "    # 3 hidden layers\n",
    "    {'hidden_layers': [512, 256, 128], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 16},\n",
    "    {'hidden_layers': [512, 256, 128], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32},\n",
    "\n",
    "    # 4 hidden layers\n",
    "    {'hidden_layers': [1024, 512, 256, 128], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 16},\n",
    "     {'hidden_layers': [1024, 512, 256, 128], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.001, 'batch_size': 16},\n",
    "    {'hidden_layers': [1024, 512, 256, 128], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.001, 'batch_size': 32},\n",
    "\n",
    "    # Custom hidden layers\n",
    "    {'hidden_layers': [160, 80, 40, 20, 10, 5], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.1, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32},\n",
    "    {'hidden_layers': [1024, 2048, 1024, 512, 1024, 256, 128], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32},\n",
    "    {'hidden_layers': [1024, 2048, 516, 256, 128, 2048, 128, 256, 512, 2048], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.2, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32},\n",
    "    {'hidden_layers': [4096, 1024, 256, 128, 64, 32], 'activation_function': 'relu', 'optimizer': 'sgd', 'dropout_rate': 0.4, 'pred': None, 'rmse': None, 'learning_rate': 0.01, 'batch_size': 32},\n",
    "]\n",
    "\n",
    "model_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "288/288 - 6s - loss: 0.4185 - val_loss: 0.1928 - 6s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 2s - loss: 0.1794 - val_loss: 0.1793 - 2s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 1s - loss: 0.1609 - val_loss: 0.1652 - 1s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 1s - loss: 0.1318 - val_loss: 0.2071 - 1s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 1s - loss: 0.1159 - val_loss: 0.1777 - 1s/epoch - 4ms/step\n",
      "Epoch 5: early stopping\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 3s - loss: 0.4095 - val_loss: 0.1600 - 3s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 1s - loss: 0.1614 - val_loss: 0.1522 - 1s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 1s - loss: 0.1436 - val_loss: 0.1544 - 1s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 1s - loss: 0.1288 - val_loss: 0.1544 - 1s/epoch - 5ms/step\n",
      "Epoch 4: early stopping\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 3s - loss: 0.8578 - val_loss: 0.6453 - 3s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 1s - loss: 0.3895 - val_loss: 0.1941 - 1s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 1s - loss: 0.1905 - val_loss: 0.1882 - 1s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 1s - loss: 0.1855 - val_loss: 0.2507 - 1s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 1s - loss: 0.1588 - val_loss: 0.1757 - 1s/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 1s - loss: 0.1527 - val_loss: 0.1835 - 1s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "288/288 - 1s - loss: 0.1480 - val_loss: 0.1844 - 1s/epoch - 5ms/step\n",
      "Epoch 7: early stopping\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 2s - loss: 0.5655 - val_loss: 0.2063 - 2s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 1s - loss: 0.1816 - val_loss: 0.1621 - 1s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 1s - loss: 0.1643 - val_loss: 0.1537 - 1s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 1s - loss: 0.1511 - val_loss: 0.1551 - 1s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 1s - loss: 0.1412 - val_loss: 0.1510 - 1s/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 1s - loss: 0.1343 - val_loss: 0.1437 - 1s/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "288/288 - 1s - loss: 0.1256 - val_loss: 0.1555 - 1s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "288/288 - 1s - loss: 0.1180 - val_loss: 0.1666 - 1s/epoch - 5ms/step\n",
      "Epoch 8: early stopping\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 2s - loss: 0.7521 - val_loss: 0.6711 - 2s/epoch - 8ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 1s - loss: 0.7069 - val_loss: 0.6667 - 1s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 1s - loss: 0.7051 - val_loss: 0.6639 - 1s/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 1s - loss: 0.7021 - val_loss: 0.6790 - 1s/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 1s - loss: 0.6975 - val_loss: 0.7032 - 1s/epoch - 4ms/step\n",
      "Epoch 5: early stopping\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 2s - loss: 0.4396 - val_loss: 0.1984 - 2s/epoch - 7ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 1s - loss: 0.1878 - val_loss: 0.1705 - 1s/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 1s - loss: 0.1713 - val_loss: 0.2086 - 1s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 1s - loss: 0.1640 - val_loss: 0.2077 - 1s/epoch - 4ms/step\n",
      "Epoch 4: early stopping\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 3s - loss: 0.6578 - val_loss: 0.1718 - 3s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 2s - loss: 0.1485 - val_loss: 0.1678 - 2s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 2s - loss: 0.1083 - val_loss: 0.1772 - 2s/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 2s - loss: 0.0920 - val_loss: 0.1717 - 2s/epoch - 7ms/step\n",
      "Epoch 4: early stopping\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 4s - loss: 1.0866 - val_loss: 0.6712 - 4s/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 2s - loss: 0.6923 - val_loss: 0.6655 - 2s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 2s - loss: 0.6916 - val_loss: 0.6750 - 2s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 2s - loss: 0.5417 - val_loss: 0.2129 - 2s/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 2s - loss: 0.1924 - val_loss: 0.2082 - 2s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 2s - loss: 0.1676 - val_loss: 0.1560 - 2s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "288/288 - 2s - loss: 0.1481 - val_loss: 0.1595 - 2s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "288/288 - 2s - loss: 0.1410 - val_loss: 0.1522 - 2s/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "288/288 - 2s - loss: 0.1384 - val_loss: 0.1542 - 2s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "288/288 - 2s - loss: 0.1343 - val_loss: 0.1545 - 2s/epoch - 7ms/step\n",
      "Epoch 10: early stopping\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 4s - loss: 0.4177 - val_loss: 0.1623 - 4s/epoch - 14ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 2s - loss: 0.1541 - val_loss: 0.1807 - 2s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 2s - loss: 0.1365 - val_loss: 0.1562 - 2s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 2s - loss: 0.1244 - val_loss: 0.1512 - 2s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 2s - loss: 0.1188 - val_loss: 0.1542 - 2s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 2s - loss: 0.1144 - val_loss: 0.1523 - 2s/epoch - 8ms/step\n",
      "Epoch 6: early stopping\n",
      "72/72 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 4s - loss: 1.1257 - val_loss: 0.5237 - 4s/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 2s - loss: 0.3885 - val_loss: 0.2597 - 2s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 2s - loss: 0.2301 - val_loss: 0.2152 - 2s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 2s - loss: 0.2011 - val_loss: 0.1954 - 2s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 2s - loss: 0.1872 - val_loss: 0.1825 - 2s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 2s - loss: 0.1771 - val_loss: 0.1784 - 2s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "288/288 - 3s - loss: 0.1702 - val_loss: 0.1712 - 3s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "288/288 - 2s - loss: 0.1640 - val_loss: 0.1726 - 2s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "288/288 - 3s - loss: 0.1578 - val_loss: 0.1640 - 3s/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "288/288 - 2s - loss: 0.1532 - val_loss: 0.1630 - 2s/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "288/288 - 2s - loss: 0.1482 - val_loss: 0.1614 - 2s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "288/288 - 3s - loss: 0.1447 - val_loss: 0.1609 - 3s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "288/288 - 3s - loss: 0.1409 - val_loss: 0.1560 - 3s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "288/288 - 2s - loss: 0.1376 - val_loss: 0.1547 - 2s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "288/288 - 2s - loss: 0.1339 - val_loss: 0.1598 - 2s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "288/288 - 2s - loss: 0.1302 - val_loss: 0.1551 - 2s/epoch - 8ms/step\n",
      "Epoch 16: early stopping\n",
      "72/72 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 5s - loss: 0.9366 - val_loss: 0.6658 - 5s/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 2s - loss: 0.6931 - val_loss: 0.6667 - 2s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 2s - loss: 0.6944 - val_loss: 0.6670 - 2s/epoch - 8ms/step\n",
      "Epoch 3: early stopping\n",
      "72/72 [==============================] - 1s 7ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 3s - loss: 0.7853 - val_loss: 0.3603 - 3s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 2s - loss: 0.2545 - val_loss: 0.2079 - 2s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 2s - loss: 0.2029 - val_loss: 0.1881 - 2s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 2s - loss: 0.1888 - val_loss: 0.1803 - 2s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 2s - loss: 0.1795 - val_loss: 0.1747 - 2s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 2s - loss: 0.1745 - val_loss: 0.1741 - 2s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "288/288 - 2s - loss: 0.1697 - val_loss: 0.1694 - 2s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "288/288 - 2s - loss: 0.1667 - val_loss: 0.1675 - 2s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "288/288 - 2s - loss: 0.1637 - val_loss: 0.1659 - 2s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "288/288 - 2s - loss: 0.1609 - val_loss: 0.1704 - 2s/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "288/288 - 2s - loss: 0.1590 - val_loss: 0.1638 - 2s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "288/288 - 2s - loss: 0.1572 - val_loss: 0.1630 - 2s/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "288/288 - 2s - loss: 0.1557 - val_loss: 0.1651 - 2s/epoch - 7ms/step\n",
      "Epoch 13: early stopping\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "576/576 - 6s - loss: 0.4006 - val_loss: 0.1788 - 6s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "576/576 - 5s - loss: 0.1697 - val_loss: 0.1766 - 5s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "576/576 - 5s - loss: 0.1515 - val_loss: 0.1530 - 5s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "576/576 - 5s - loss: 0.1403 - val_loss: 0.1696 - 5s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "576/576 - 5s - loss: 0.1311 - val_loss: 0.1490 - 5s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "576/576 - 4s - loss: 0.1201 - val_loss: 0.1569 - 4s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "576/576 - 5s - loss: 0.1113 - val_loss: 0.1565 - 5s/epoch - 9ms/step\n",
      "Epoch 7: early stopping\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 3s - loss: 0.5941 - val_loss: 0.1833 - 3s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 2s - loss: 0.1846 - val_loss: 0.1702 - 2s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 2s - loss: 0.1608 - val_loss: 0.1540 - 2s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 2s - loss: 0.1475 - val_loss: 0.1585 - 2s/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 2s - loss: 0.1382 - val_loss: 0.1496 - 2s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 2s - loss: 0.1271 - val_loss: 0.1512 - 2s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "288/288 - 2s - loss: 0.1191 - val_loss: 0.1547 - 2s/epoch - 7ms/step\n",
      "Epoch 7: early stopping\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "576/576 - 11s - loss: 0.4511 - val_loss: 0.1723 - 11s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "576/576 - 12s - loss: 0.1756 - val_loss: 0.1677 - 12s/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "576/576 - 12s - loss: 0.1528 - val_loss: 0.1584 - 12s/epoch - 21ms/step\n",
      "Epoch 4/100\n",
      "576/576 - 12s - loss: 0.1399 - val_loss: 0.2132 - 12s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "576/576 - 10s - loss: 0.1288 - val_loss: 0.1487 - 10s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "576/576 - 11s - loss: 0.1184 - val_loss: 0.1435 - 11s/epoch - 18ms/step\n",
      "Epoch 7/100\n",
      "576/576 - 11s - loss: 0.1070 - val_loss: 0.1516 - 11s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "576/576 - 12s - loss: 0.0982 - val_loss: 0.1486 - 12s/epoch - 21ms/step\n",
      "Epoch 8: early stopping\n",
      "72/72 [==============================] - 1s 4ms/step\n",
      "Epoch 1/100\n",
      "576/576 - 14s - loss: 0.8020 - val_loss: 0.2483 - 14s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "576/576 - 11s - loss: 0.2154 - val_loss: 0.1869 - 11s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "576/576 - 10s - loss: 0.1819 - val_loss: 0.1716 - 10s/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "576/576 - 10s - loss: 0.1670 - val_loss: 0.1661 - 10s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "576/576 - 11s - loss: 0.1561 - val_loss: 0.1596 - 11s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "576/576 - 10s - loss: 0.1475 - val_loss: 0.1522 - 10s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "576/576 - 10s - loss: 0.1406 - val_loss: 0.1499 - 10s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "576/576 - 10s - loss: 0.1343 - val_loss: 0.1496 - 10s/epoch - 18ms/step\n",
      "Epoch 9/100\n",
      "576/576 - 10s - loss: 0.1278 - val_loss: 0.1499 - 10s/epoch - 18ms/step\n",
      "Epoch 9: early stopping\n",
      "72/72 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 6s - loss: 1.1434 - val_loss: 0.5128 - 6s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 5s - loss: 0.3767 - val_loss: 0.2431 - 5s/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 5s - loss: 0.2237 - val_loss: 0.2035 - 5s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 5s - loss: 0.1950 - val_loss: 0.1851 - 5s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 5s - loss: 0.1809 - val_loss: 0.1759 - 5s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 5s - loss: 0.1710 - val_loss: 0.1706 - 5s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "288/288 - 5s - loss: 0.1631 - val_loss: 0.1747 - 5s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "288/288 - 5s - loss: 0.1570 - val_loss: 0.1613 - 5s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "288/288 - 5s - loss: 0.1516 - val_loss: 0.1626 - 5s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "288/288 - 5s - loss: 0.1469 - val_loss: 0.1640 - 5s/epoch - 16ms/step\n",
      "Epoch 10: early stopping\n",
      "72/72 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 3s - loss: 0.8561 - val_loss: 0.5967 - 3s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 1s - loss: 0.3367 - val_loss: 0.2072 - 793ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 1s - loss: 0.2180 - val_loss: 0.1645 - 789ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 1s - loss: 0.2052 - val_loss: 0.1610 - 792ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 1s - loss: 0.2009 - val_loss: 0.1625 - 749ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 1s - loss: 0.1847 - val_loss: 0.1530 - 791ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "288/288 - 1s - loss: 0.1818 - val_loss: 0.1703 - 750ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "288/288 - 1s - loss: 0.1754 - val_loss: 0.1516 - 793ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "288/288 - 1s - loss: 0.1712 - val_loss: 0.1501 - 817ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "288/288 - 1s - loss: 0.1632 - val_loss: 0.1484 - 798ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "288/288 - 1s - loss: 0.1643 - val_loss: 0.1594 - 852ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "288/288 - 1s - loss: 0.1526 - val_loss: 0.1524 - 747ms/epoch - 3ms/step\n",
      "Epoch 12: early stopping\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 16s - loss: 0.7189 - val_loss: 0.3491 - 16s/epoch - 55ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 14s - loss: 0.2005 - val_loss: 0.1674 - 14s/epoch - 50ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 14s - loss: 0.1626 - val_loss: 0.1534 - 14s/epoch - 48ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 14s - loss: 0.1461 - val_loss: 0.1499 - 14s/epoch - 48ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 14s - loss: 0.1342 - val_loss: 0.1506 - 14s/epoch - 49ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 14s - loss: 0.1225 - val_loss: 0.1559 - 14s/epoch - 48ms/step\n",
      "Epoch 6: early stopping\n",
      "72/72 [==============================] - 1s 9ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 17s - loss: 0.8638 - val_loss: 0.6771 - 17s/epoch - 59ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 15s - loss: 0.6912 - val_loss: 0.6424 - 15s/epoch - 51ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 14s - loss: 0.3239 - val_loss: 0.1901 - 14s/epoch - 49ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 17s - loss: 0.1809 - val_loss: 0.1556 - 17s/epoch - 59ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 14s - loss: 0.1553 - val_loss: 0.1590 - 14s/epoch - 49ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 14s - loss: 0.1455 - val_loss: 0.1631 - 14s/epoch - 49ms/step\n",
      "Epoch 6: early stopping\n",
      "72/72 [==============================] - 1s 9ms/step\n",
      "Epoch 1/100\n",
      "288/288 - 22s - loss: 0.5205 - val_loss: 0.2113 - 22s/epoch - 75ms/step\n",
      "Epoch 2/100\n",
      "288/288 - 20s - loss: 0.1766 - val_loss: 0.1555 - 20s/epoch - 69ms/step\n",
      "Epoch 3/100\n",
      "288/288 - 18s - loss: 0.1547 - val_loss: 0.1529 - 18s/epoch - 62ms/step\n",
      "Epoch 4/100\n",
      "288/288 - 18s - loss: 0.1423 - val_loss: 0.1599 - 18s/epoch - 64ms/step\n",
      "Epoch 5/100\n",
      "288/288 - 18s - loss: 0.1292 - val_loss: 0.1489 - 18s/epoch - 64ms/step\n",
      "Epoch 6/100\n",
      "288/288 - 18s - loss: 0.1169 - val_loss: 0.1463 - 18s/epoch - 63ms/step\n",
      "Epoch 7/100\n",
      "288/288 - 18s - loss: 0.1055 - val_loss: 0.1601 - 18s/epoch - 62ms/step\n",
      "Epoch 8/100\n",
      "288/288 - 18s - loss: 0.0985 - val_loss: 0.1710 - 18s/epoch - 64ms/step\n",
      "Epoch 8: early stopping\n",
      "72/72 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "model_results = []\n",
    "\n",
    "for model in model_types:\n",
    "    hidden_layer = model['hidden_layers']\n",
    "    activation_function = model['activation_function']\n",
    "    optimizer = model['optimizer']\n",
    "    dropout_rate = model['dropout_rate']\n",
    "    learning_rate = model['learning_rate']\n",
    "    batch_size = model['batch_size']\n",
    "    \n",
    "    results = model_tester(\n",
    "        hidden_layers=hidden_layer, \n",
    "        learning_rate=learning_rate, \n",
    "        optimizer=optimizer,\n",
    "        activation_function=activation_function, \n",
    "        dropout_rate=dropout_rate, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    model_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>pred</th>\n",
       "      <th>rmse</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.0659337], [3.0850768], [3.7099075], [3.375...</td>\n",
       "      <td>0.406442</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.8591], [3.111888], [4.1219554], [3.3229852...</td>\n",
       "      <td>0.390160</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.7307565], [2.8398578], [4.0438614], [3.230...</td>\n",
       "      <td>0.419181</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.7938712], [3.0363688], [3.9260564], [3.181...</td>\n",
       "      <td>0.379123</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.6356876], [3.6353858], [3.6358178], [3.635...</td>\n",
       "      <td>0.814821</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.0247226], [3.0311], [3.7575817], [2.995162...</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.1681595], [3.0768342], [3.589417], [3.2312...</td>\n",
       "      <td>0.409662</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.8237984], [3.0899308], [4.1797376], [3.250...</td>\n",
       "      <td>0.390158</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.851713], [3.1508033], [3.898393], [3.21256...</td>\n",
       "      <td>0.388847</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.9340086], [3.0584044], [3.8331156], [3.170...</td>\n",
       "      <td>0.393279</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.6026187], [3.6025891], [3.6023116], [3.602...</td>\n",
       "      <td>0.815951</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.0154762], [3.0775533], [3.953237], [3.0974...</td>\n",
       "      <td>0.403685</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.714936], [3.2241406], [3.9366696], [3.2821...</td>\n",
       "      <td>0.386032</td>\n",
       "      <td>0.010</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.1058564], [3.091796], [3.8090782], [3.1667...</td>\n",
       "      <td>0.386827</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1024, 512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.6520832], [3.0426724], [3.9229772], [3.078...</td>\n",
       "      <td>0.378764</td>\n",
       "      <td>0.010</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1024, 512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.9696424], [3.0523381], [3.8083546], [3.100...</td>\n",
       "      <td>0.386717</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1024, 512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.0353584], [3.014902], [3.7259915], [3.1107...</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[160, 80, 40, 20, 10, 5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[3.0342765], [3.096476], [3.8729286], [3.2239...</td>\n",
       "      <td>0.385183</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1024, 2048, 1024, 512, 1024, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.893384], [3.1639557], [3.8077512], [3.2444...</td>\n",
       "      <td>0.387191</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1024, 2048, 516, 256, 128, 2048, 128, 256, 51...</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.124739], [3.1319902], [3.6939962], [3.0975...</td>\n",
       "      <td>0.394488</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[4096, 1024, 256, 128, 64, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[[2.9342074], [3.2004597], [3.940884], [3.2484...</td>\n",
       "      <td>0.382503</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        hidden_layers activation_function  \\\n",
       "0                                      [256, 128, 64]                relu   \n",
       "1                                      [256, 128, 64]             sigmoid   \n",
       "2                                      [256, 128, 64]                tanh   \n",
       "3                                      [256, 128, 64]                relu   \n",
       "4                                      [256, 128, 64]             sigmoid   \n",
       "5                                      [256, 128, 64]                tanh   \n",
       "6                                 [512, 256, 128, 64]                relu   \n",
       "7                                 [512, 256, 128, 64]             sigmoid   \n",
       "8                                 [512, 256, 128, 64]                tanh   \n",
       "9                                 [512, 256, 128, 64]                relu   \n",
       "10                                [512, 256, 128, 64]             sigmoid   \n",
       "11                                [512, 256, 128, 64]                tanh   \n",
       "12                                    [512, 256, 128]                relu   \n",
       "13                                    [512, 256, 128]                relu   \n",
       "14                              [1024, 512, 256, 128]                relu   \n",
       "15                              [1024, 512, 256, 128]                relu   \n",
       "16                              [1024, 512, 256, 128]                relu   \n",
       "17                           [160, 80, 40, 20, 10, 5]                relu   \n",
       "18            [1024, 2048, 1024, 512, 1024, 256, 128]                relu   \n",
       "19  [1024, 2048, 516, 256, 128, 2048, 128, 256, 51...                relu   \n",
       "20                     [4096, 1024, 256, 128, 64, 32]                relu   \n",
       "\n",
       "   optimizer  dropout_rate                                               pred  \\\n",
       "0       adam           0.2  [[3.0659337], [3.0850768], [3.7099075], [3.375...   \n",
       "1       adam           0.2  [[2.8591], [3.111888], [4.1219554], [3.3229852...   \n",
       "2       adam           0.2  [[2.7307565], [2.8398578], [4.0438614], [3.230...   \n",
       "3        sgd           0.2  [[2.7938712], [3.0363688], [3.9260564], [3.181...   \n",
       "4        sgd           0.2  [[3.6356876], [3.6353858], [3.6358178], [3.635...   \n",
       "5        sgd           0.2  [[3.0247226], [3.0311], [3.7575817], [2.995162...   \n",
       "6       adam           0.2  [[3.1681595], [3.0768342], [3.589417], [3.2312...   \n",
       "7       adam           0.2  [[2.8237984], [3.0899308], [4.1797376], [3.250...   \n",
       "8       adam           0.2  [[2.851713], [3.1508033], [3.898393], [3.21256...   \n",
       "9        sgd           0.2  [[2.9340086], [3.0584044], [3.8331156], [3.170...   \n",
       "10       sgd           0.2  [[3.6026187], [3.6025891], [3.6023116], [3.602...   \n",
       "11       sgd           0.2  [[3.0154762], [3.0775533], [3.953237], [3.0974...   \n",
       "12       sgd           0.2  [[2.714936], [3.2241406], [3.9366696], [3.2821...   \n",
       "13       sgd           0.2  [[3.1058564], [3.091796], [3.8090782], [3.1667...   \n",
       "14       sgd           0.2  [[2.6520832], [3.0426724], [3.9229772], [3.078...   \n",
       "15       sgd           0.2  [[2.9696424], [3.0523381], [3.8083546], [3.100...   \n",
       "16       sgd           0.2  [[3.0353584], [3.014902], [3.7259915], [3.1107...   \n",
       "17       sgd           0.1  [[3.0342765], [3.096476], [3.8729286], [3.2239...   \n",
       "18       sgd           0.2  [[2.893384], [3.1639557], [3.8077512], [3.2444...   \n",
       "19       sgd           0.2  [[3.124739], [3.1319902], [3.6939962], [3.0975...   \n",
       "20       sgd           0.4  [[2.9342074], [3.2004597], [3.940884], [3.2484...   \n",
       "\n",
       "        rmse  learning_rate  batch_size  \n",
       "0   0.406442          0.010          32  \n",
       "1   0.390160          0.010          32  \n",
       "2   0.419181          0.010          32  \n",
       "3   0.379123          0.010          32  \n",
       "4   0.814821          0.010          32  \n",
       "5   0.412946          0.010          32  \n",
       "6   0.409662          0.001          32  \n",
       "7   0.390158          0.001          32  \n",
       "8   0.388847          0.001          32  \n",
       "9   0.393279          0.001          32  \n",
       "10  0.815951          0.001          32  \n",
       "11  0.403685          0.001          32  \n",
       "12  0.386032          0.010          16  \n",
       "13  0.386827          0.010          32  \n",
       "14  0.378764          0.010          16  \n",
       "15  0.386717          0.001          16  \n",
       "16  0.401641          0.001          32  \n",
       "17  0.385183          0.010          32  \n",
       "18  0.387191          0.010          32  \n",
       "19  0.394488          0.010          32  \n",
       "20  0.382503          0.010          32  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model types with model_results\n",
    "for i, result in enumerate(model_results):\n",
    "    model_types[i]['rmse'] = result[0]\n",
    "    model_types[i]['pred'] = result[1]  \n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "model_results = pd.DataFrame(model_types)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model results\n",
    "best = model_results[1]\n",
    "\n",
    "print(\"Score (RMSE): {}\".format(best[0]))\n",
    "chart_regression(best[1].flatten(),y_test)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"{}. Business name: {}, Rating: {}, Predicted Rating: {}\".format(i+1,business.iloc[i]['name'],y[i],best[1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurant Specific Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data from JSON to Pandas\n",
    "reviews = pd.read_json('yelp_academic_dataset_review.json', lines=True, nrows=1000000)\n",
    "\n",
    "business = pd.read_json('yelp_academic_dataset_business.json', lines=True, nrows=1000000)\n",
    "\n",
    "# Rename to distinguish star ratings after join\n",
    "reviews = reviews.rename(columns={'stars': 'review_rating'})\n",
    "business = business.rename(columns={'stars': 'business_rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Doctors, Traditional Chinese Medicine, Naturop...\n",
       "1    Shipping Centers, Local Services, Notaries, Ma...\n",
       "2    Department Stores, Shopping, Fashion, Home & G...\n",
       "3    Restaurants, Food, Bubble Tea, Coffee & Tea, B...\n",
       "4                            Brewpubs, Breweries, Food\n",
       "Name: categories, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business['categories'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before :  (59699, 15)\n",
      "After :  (33217, 16)\n"
     ]
    }
   ],
   "source": [
    "# Add Location Column\n",
    "business['location'] = business['city'] + \", \" + business['state']\n",
    "\n",
    "# Filter businesses out (review_count < 20 and null business_id & review_count)\n",
    "business =  business[business.review_count > 20]\n",
    "\n",
    "print(\"Before : \", business.shape)\n",
    "business['is_restaurant'] = business['categories'].str.contains('Restaurants', case=False, na=False)\n",
    "business =  business[business['is_restaurant'] == True]\n",
    "\n",
    "print(\"After : \", business.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review_id', 'user_id', 'business_id', 'review_rating', 'useful',\n",
      "       'funny', 'cool', 'text', 'date', 'name', 'address', 'city', 'state',\n",
      "       'postal_code', 'latitude', 'longitude', 'business_rating',\n",
      "       'review_count', 'is_open', 'attributes', 'categories', 'hours',\n",
      "       'location', 'is_restaurant'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>business_rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>location</th>\n",
       "      <th>is_restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>...</td>\n",
       "      <td>40.210196</td>\n",
       "      <td>-75.223639</td>\n",
       "      <td>3.0</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NoiseLevel': 'u'average'', 'HasTV': 'False',...</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch, Food, Juice B...</td>\n",
       "      <td>{'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...</td>\n",
       "      <td>North Wales, PA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "      <td>Kettle Restaurant</td>\n",
       "      <td>...</td>\n",
       "      <td>32.207233</td>\n",
       "      <td>-110.980864</td>\n",
       "      <td>3.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsReservations': 'True', 'BusinessP...</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>Zaika</td>\n",
       "      <td>...</td>\n",
       "      <td>40.079848</td>\n",
       "      <td>-75.025080</td>\n",
       "      <td>4.0</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Caters': 'True', 'Ambience': '{'romantic': F...</td>\n",
       "      <td>Halal, Pakistani, Restaurants, Indian</td>\n",
       "      <td>{'Tuesday': '11:0-21:0', 'Wednesday': '11:0-21...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>Melt</td>\n",
       "      <td>...</td>\n",
       "      <td>29.962102</td>\n",
       "      <td>-90.087958</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BusinessParking': '{'garage': False, 'street...</td>\n",
       "      <td>Sandwiches, Beer, Wine &amp; Spirits, Bars, Food, ...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Friday': '11:0-17:0', '...</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JrIxlS1TzJ-iCu79ul40cQ</td>\n",
       "      <td>eUta8W_HdHMXPzLBBZhL1A</td>\n",
       "      <td>04UD14gamNjLY0IDYVhHJg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I am a long term frequent customer of this est...</td>\n",
       "      <td>2015-09-23 23:10:31</td>\n",
       "      <td>Dmitri's</td>\n",
       "      <td>...</td>\n",
       "      <td>39.938013</td>\n",
       "      <td>-75.148131</td>\n",
       "      <td>4.0</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BusinessParking': '{'garage': False, 'street...</td>\n",
       "      <td>Mediterranean, Restaurants, Seafood, Greek</td>\n",
       "      <td>{'Wednesday': '17:30-21:0', 'Thursday': '17:30...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "2  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "3  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "4  JrIxlS1TzJ-iCu79ul40cQ  eUta8W_HdHMXPzLBBZhL1A  04UD14gamNjLY0IDYVhHJg   \n",
       "\n",
       "   review_rating  useful  funny  cool  \\\n",
       "0              3       0      0     0   \n",
       "1              3       0      0     0   \n",
       "2              5       1      0     1   \n",
       "3              4       1      0     1   \n",
       "4              1       1      2     1   \n",
       "\n",
       "                                                text                date  \\\n",
       "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11   \n",
       "1  Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30   \n",
       "2  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03   \n",
       "3  Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15   \n",
       "4  I am a long term frequent customer of this est... 2015-09-23 23:10:31   \n",
       "\n",
       "                           name  ...   latitude   longitude business_rating  \\\n",
       "0  Turning Point of North Wales  ...  40.210196  -75.223639             3.0   \n",
       "1             Kettle Restaurant  ...  32.207233 -110.980864             3.5   \n",
       "2                         Zaika  ...  40.079848  -75.025080             4.0   \n",
       "3                          Melt  ...  29.962102  -90.087958             4.0   \n",
       "4                      Dmitri's  ...  39.938013  -75.148131             4.0   \n",
       "\n",
       "  review_count  is_open                                         attributes  \\\n",
       "0          169        1  {'NoiseLevel': 'u'average'', 'HasTV': 'False',...   \n",
       "1           47        1  {'RestaurantsReservations': 'True', 'BusinessP...   \n",
       "2          181        1  {'Caters': 'True', 'Ambience': '{'romantic': F...   \n",
       "3           32        0  {'BusinessParking': '{'garage': False, 'street...   \n",
       "4          273        0  {'BusinessParking': '{'garage': False, 'street...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Restaurants, Breakfast & Brunch, Food, Juice B...   \n",
       "1                    Restaurants, Breakfast & Brunch   \n",
       "2              Halal, Pakistani, Restaurants, Indian   \n",
       "3  Sandwiches, Beer, Wine & Spirits, Bars, Food, ...   \n",
       "4         Mediterranean, Restaurants, Seafood, Greek   \n",
       "\n",
       "                                               hours          location  \\\n",
       "0  {'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...   North Wales, PA   \n",
       "1                                               None        Tucson, AZ   \n",
       "2  {'Tuesday': '11:0-21:0', 'Wednesday': '11:0-21...  Philadelphia, PA   \n",
       "3  {'Monday': '0:0-0:0', 'Friday': '11:0-17:0', '...   New Orleans, LA   \n",
       "4  {'Wednesday': '17:30-21:0', 'Thursday': '17:30...  Philadelphia, PA   \n",
       "\n",
       "  is_restaurant  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the business and reviews together \n",
    "all_reviews = pd.merge(reviews,business, on='business_id') \n",
    "\n",
    "print(all_reviews.columns)\n",
    "all_reviews.head()\n",
    "# all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the business's reviews into one text\n",
    "business_reviews = all_reviews.groupby('business_id')['text'].sum()\n",
    "\n",
    "# # Create a dataframe with the business and its all its cooresponding reviews\n",
    "df_business_reviews = pd.DataFrame({\n",
    "  'business_id' : business_reviews.index, \n",
    "  'all_reviews' : business_reviews.values,\n",
    "})\n",
    "\n",
    "df_business_reviews = pd.merge(df_business_reviews, business[['business_id', 'location', 'review_count', 'business_rating']], on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abington Township, PA</th>\n",
       "      <th>Abington, PA</th>\n",
       "      <th>Affton, MO</th>\n",
       "      <th>Aldan, PA</th>\n",
       "      <th>Alton, IL</th>\n",
       "      <th>Ambler, PA</th>\n",
       "      <th>Antioch, TN</th>\n",
       "      <th>Apollo Beach, FL</th>\n",
       "      <th>Arabi, LA</th>\n",
       "      <th>Ardmore, PA</th>\n",
       "      <th>...</th>\n",
       "      <th>Wynnewood, PA</th>\n",
       "      <th>Yardley, PA</th>\n",
       "      <th>Yeadon, PA</th>\n",
       "      <th>Zephyrhills, FL</th>\n",
       "      <th>Zionsville, IN</th>\n",
       "      <th>wilmington, DE</th>\n",
       "      <th>business_id</th>\n",
       "      <th>all_reviews</th>\n",
       "      <th>review_count</th>\n",
       "      <th>business_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>--ZVrH2X2QXBFdCilbirsw</td>\n",
       "      <td>This place is sadly perm closed. I was hoping ...</td>\n",
       "      <td>-0.490067</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0TffRSXXIlBYVbb5AwfTg</td>\n",
       "      <td>We went for my husbands birthday in a fairly l...</td>\n",
       "      <td>4.569832</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0jzoPt3UeXn6FUXVQvyPg</td>\n",
       "      <td>Went to the movies downtown and decided to gra...</td>\n",
       "      <td>0.089564</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1MhPXk1FglglUAmuPLIGg</td>\n",
       "      <td>Great food and drink. The staff are always fri...</td>\n",
       "      <td>-0.133736</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2Axhv9AZ_n7qjQefECpVw</td>\n",
       "      <td>The service was excellent, extremely friendly....</td>\n",
       "      <td>-0.542329</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Abington Township, PA  Abington, PA  Affton, MO  Aldan, PA  Alton, IL  \\\n",
       "0                  False         False       False      False      False   \n",
       "1                  False         False       False      False      False   \n",
       "2                  False         False       False      False      False   \n",
       "3                  False         False       False      False      False   \n",
       "4                  False         False       False      False      False   \n",
       "\n",
       "   Ambler, PA  Antioch, TN  Apollo Beach, FL  Arabi, LA  Ardmore, PA  ...  \\\n",
       "0       False        False             False      False         True  ...   \n",
       "1       False        False             False      False        False  ...   \n",
       "2       False        False             False      False        False  ...   \n",
       "3       False        False             False      False        False  ...   \n",
       "4       False        False             False      False        False  ...   \n",
       "\n",
       "   Wynnewood, PA  Yardley, PA  Yeadon, PA  Zephyrhills, FL  Zionsville, IN  \\\n",
       "0          False        False       False            False           False   \n",
       "1          False        False       False            False           False   \n",
       "2          False        False       False            False           False   \n",
       "3          False        False       False            False           False   \n",
       "4          False        False       False            False           False   \n",
       "\n",
       "   wilmington, DE             business_id  \\\n",
       "0           False  --ZVrH2X2QXBFdCilbirsw   \n",
       "1           False  -0TffRSXXIlBYVbb5AwfTg   \n",
       "2           False  -0jzoPt3UeXn6FUXVQvyPg   \n",
       "3           False  -1MhPXk1FglglUAmuPLIGg   \n",
       "4           False  -2Axhv9AZ_n7qjQefECpVw   \n",
       "\n",
       "                                         all_reviews  review_count  \\\n",
       "0  This place is sadly perm closed. I was hoping ...     -0.490067   \n",
       "1  We went for my husbands birthday in a fairly l...      4.569832   \n",
       "2  Went to the movies downtown and decided to gra...      0.089564   \n",
       "3  Great food and drink. The staff are always fri...     -0.133736   \n",
       "4  The service was excellent, extremely friendly....     -0.542329   \n",
       "\n",
       "   business_rating  \n",
       "0              4.5  \n",
       "1              4.5  \n",
       "2              4.5  \n",
       "3              4.0  \n",
       "4              3.5  \n",
       "\n",
       "[5 rows x 477 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding for location\n",
    "df_encoded = pd.get_dummies(df_business_reviews['location'])\n",
    "df_business_reviews = pd.concat([df_encoded, df_business_reviews], axis=1)\n",
    "\n",
    "# Drop location column now that one)\n",
    "df_business_reviews.drop(['location'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Replace nulls with mean and normalize review count for the business\n",
    "missing_median(df_business_reviews, 'review_count')\n",
    "encode_numeric_zscore(df_business_reviews, 'review_count')\n",
    "\n",
    "df_business_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_business_reviews['all_reviews']\n",
    "text.head()\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english',max_features=1000,min_df=1)\n",
    "# Fit and transform the aggregated reviews into a TF-IDF matrix\n",
    "tfidf_wm = vectorizer.fit_transform(text)\n",
    "\n",
    "# Retrieve the feature names (i.e., the vocabulary)\n",
    "tfidf_tokens = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame from the TF-IDF matrix for easier viewing\n",
    "df_tfidfvect = pd.DataFrame(data=tfidf_wm.toarray(), columns=tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5123, 1000) (5123,) (1281, 1000) (1281,)\n"
     ]
    }
   ],
   "source": [
    "# Combine x and y into a single DataFrame\n",
    "df_combined = pd.concat([df_tfidfvect, df_business_reviews['business_rating']], axis=1)\n",
    "\n",
    "# Use the to_xy function to convert the DataFrame to x and y arrays\n",
    "x, y = to_xy(df_combined, 'business_rating')\n",
    "\n",
    "# Now split the transformed data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Check the shape of the resulting arrays\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "161/161 - 3s - loss: 0.4260 - val_loss: 0.1454 - 3s/epoch - 17ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.1256 - val_loss: 0.1478 - 868ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.1094 - val_loss: 0.1287 - 938ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.0890 - val_loss: 0.1286 - 899ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.0782 - val_loss: 0.1365 - 816ms/epoch - 5ms/step\n",
      "Epoch 5: early stopping\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 2s - loss: 0.7740 - val_loss: 0.5580 - 2s/epoch - 14ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.5469 - val_loss: 0.5360 - 877ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.5466 - val_loss: 0.5459 - 824ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.4370 - val_loss: 0.2051 - 881ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.1469 - val_loss: 0.1336 - 886ms/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 1s - loss: 0.1094 - val_loss: 0.1243 - 1s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "161/161 - 1s - loss: 0.0905 - val_loss: 0.1581 - 918ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "161/161 - 1s - loss: 0.0809 - val_loss: 0.1170 - 915ms/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "161/161 - 1s - loss: 0.0757 - val_loss: 0.1304 - 903ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "161/161 - 1s - loss: 0.0689 - val_loss: 0.1335 - 916ms/epoch - 6ms/step\n",
      "Epoch 10: early stopping\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 2s - loss: 0.8837 - val_loss: 0.4462 - 2s/epoch - 14ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.2007 - val_loss: 0.1274 - 857ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.1243 - val_loss: 0.1889 - 797ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.1066 - val_loss: 0.1432 - 846ms/epoch - 5ms/step\n",
      "Epoch 4: early stopping\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 2s - loss: 0.7409 - val_loss: 0.2917 - 2s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.1750 - val_loss: 0.1298 - 975ms/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.1296 - val_loss: 0.1252 - 1s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.1165 - val_loss: 0.1161 - 942ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.1048 - val_loss: 0.1203 - 879ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 1s - loss: 0.0980 - val_loss: 0.3719 - 733ms/epoch - 5ms/step\n",
      "Epoch 6: early stopping\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 2s - loss: 0.6314 - val_loss: 0.5625 - 2s/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.5501 - val_loss: 0.5418 - 855ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.5514 - val_loss: 0.5539 - 810ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.5472 - val_loss: 0.6160 - 856ms/epoch - 5ms/step\n",
      "Epoch 4: early stopping\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 2s - loss: 0.4611 - val_loss: 0.1400 - 2s/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.1463 - val_loss: 0.1446 - 820ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.1270 - val_loss: 0.1289 - 834ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.1172 - val_loss: 0.1150 - 821ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.1116 - val_loss: 0.1806 - 848ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 1s - loss: 0.1078 - val_loss: 0.1384 - 862ms/epoch - 5ms/step\n",
      "Epoch 6: early stopping\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 3s - loss: 0.8522 - val_loss: 0.1543 - 3s/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.1088 - val_loss: 0.1307 - 1s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.0810 - val_loss: 0.1377 - 1s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.0630 - val_loss: 0.1249 - 1s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.0496 - val_loss: 0.1268 - 1s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 1s - loss: 0.0425 - val_loss: 0.1234 - 1s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "161/161 - 1s - loss: 0.0356 - val_loss: 0.1327 - 1s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "161/161 - 1s - loss: 0.0276 - val_loss: 0.1473 - 1s/epoch - 7ms/step\n",
      "Epoch 8: early stopping\n",
      "41/41 [==============================] - 0s 4ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 3s - loss: 0.7365 - val_loss: 0.5368 - 3s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.5425 - val_loss: 0.5559 - 1s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.5218 - val_loss: 0.3798 - 1s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.1939 - val_loss: 0.1566 - 1s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.1301 - val_loss: 0.1183 - 1s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 1s - loss: 0.1092 - val_loss: 0.1279 - 1s/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "161/161 - 1s - loss: 0.1009 - val_loss: 0.1082 - 1s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "161/161 - 1s - loss: 0.0951 - val_loss: 0.1130 - 1s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "161/161 - 1s - loss: 0.0907 - val_loss: 0.1376 - 1s/epoch - 7ms/step\n",
      "Epoch 9: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 3s - loss: 0.4997 - val_loss: 0.1246 - 3s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.1115 - val_loss: 0.1215 - 1s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.1021 - val_loss: 0.1136 - 1s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.0840 - val_loss: 0.1160 - 1s/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.0794 - val_loss: 0.1443 - 1s/epoch - 8ms/step\n",
      "Epoch 5: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 3s - loss: 1.4386 - val_loss: 0.4805 - 3s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 2s - loss: 0.4262 - val_loss: 0.3627 - 2s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.2952 - val_loss: 0.2179 - 1s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.1889 - val_loss: 0.1572 - 1s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.1583 - val_loss: 0.1432 - 1s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 1s - loss: 0.1449 - val_loss: 0.1342 - 1s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "161/161 - 1s - loss: 0.1348 - val_loss: 0.1320 - 1s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "161/161 - 1s - loss: 0.1291 - val_loss: 0.1273 - 1s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "161/161 - 1s - loss: 0.1238 - val_loss: 0.1230 - 1s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "161/161 - 1s - loss: 0.1187 - val_loss: 0.1216 - 1s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "161/161 - 1s - loss: 0.1153 - val_loss: 0.1187 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "161/161 - 1s - loss: 0.1114 - val_loss: 0.1231 - 1s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "161/161 - 1s - loss: 0.1089 - val_loss: 0.1161 - 1s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "161/161 - 1s - loss: 0.1061 - val_loss: 0.1157 - 1s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "161/161 - 2s - loss: 0.1032 - val_loss: 0.1198 - 2s/epoch - 10ms/step\n",
      "Epoch 15: early stopping\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 6s - loss: 0.9801 - val_loss: 0.5366 - 6s/epoch - 38ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.5407 - val_loss: 0.5454 - 1s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.5423 - val_loss: 0.5457 - 1s/epoch - 7ms/step\n",
      "Epoch 3: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 2s - loss: 0.8449 - val_loss: 0.4527 - 2s/epoch - 14ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.3595 - val_loss: 0.2494 - 1s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.1990 - val_loss: 0.1640 - 1s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.1621 - val_loss: 0.1454 - 1s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.1473 - val_loss: 0.1459 - 1s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 1s - loss: 0.1372 - val_loss: 0.1308 - 1s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "161/161 - 1s - loss: 0.1299 - val_loss: 0.1265 - 1s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "161/161 - 1s - loss: 0.1252 - val_loss: 0.1236 - 1s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "161/161 - 1s - loss: 0.1212 - val_loss: 0.1217 - 1s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "161/161 - 1s - loss: 0.1180 - val_loss: 0.1235 - 1s/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "161/161 - 1s - loss: 0.1150 - val_loss: 0.1221 - 1s/epoch - 8ms/step\n",
      "Epoch 11: early stopping\n",
      "41/41 [==============================] - 0s 7ms/step\n",
      "Epoch 1/100\n",
      "321/321 - 4s - loss: 0.4675 - val_loss: 0.1379 - 4s/epoch - 11ms/step\n",
      "Epoch 2/100\n",
      "321/321 - 2s - loss: 0.1297 - val_loss: 0.1875 - 2s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "321/321 - 3s - loss: 0.1105 - val_loss: 0.1728 - 3s/epoch - 9ms/step\n",
      "Epoch 3: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 2s - loss: 0.7425 - val_loss: 0.2547 - 2s/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.1541 - val_loss: 0.1242 - 1s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.1204 - val_loss: 0.1207 - 1s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.1110 - val_loss: 0.1115 - 1s/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.0994 - val_loss: 0.1294 - 1s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 1s - loss: 0.0945 - val_loss: 0.3866 - 1s/epoch - 7ms/step\n",
      "Epoch 6: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "321/321 - 6s - loss: 0.4218 - val_loss: 0.6968 - 6s/epoch - 18ms/step\n",
      "Epoch 2/100\n",
      "321/321 - 5s - loss: 0.1316 - val_loss: 0.1291 - 5s/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "321/321 - 5s - loss: 0.1080 - val_loss: 0.1396 - 5s/epoch - 15ms/step\n",
      "Epoch 4/100\n",
      "321/321 - 5s - loss: 0.0955 - val_loss: 0.1592 - 5s/epoch - 16ms/step\n",
      "Epoch 4: early stopping\n",
      "41/41 [==============================] - 0s 7ms/step\n",
      "Epoch 1/100\n",
      "321/321 - 6s - loss: 1.0086 - val_loss: 0.4215 - 6s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "321/321 - 5s - loss: 0.2367 - val_loss: 0.1627 - 5s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "321/321 - 6s - loss: 0.1496 - val_loss: 0.1380 - 6s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "321/321 - 6s - loss: 0.1315 - val_loss: 0.1289 - 6s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "321/321 - 6s - loss: 0.1199 - val_loss: 0.1214 - 6s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "321/321 - 7s - loss: 0.1118 - val_loss: 0.1192 - 7s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "321/321 - 5s - loss: 0.1062 - val_loss: 0.1236 - 5s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "321/321 - 5s - loss: 0.1011 - val_loss: 0.1338 - 5s/epoch - 16ms/step\n",
      "Epoch 8: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 4s - loss: 1.4374 - val_loss: 0.4831 - 4s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 3s - loss: 0.4282 - val_loss: 0.3674 - 3s/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 3s - loss: 0.2873 - val_loss: 0.2149 - 3s/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 3s - loss: 0.1845 - val_loss: 0.1580 - 3s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 3s - loss: 0.1557 - val_loss: 0.1446 - 3s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 3s - loss: 0.1427 - val_loss: 0.1361 - 3s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "161/161 - 3s - loss: 0.1327 - val_loss: 0.1316 - 3s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "161/161 - 3s - loss: 0.1256 - val_loss: 0.1264 - 3s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "161/161 - 3s - loss: 0.1198 - val_loss: 0.1251 - 3s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "161/161 - 3s - loss: 0.1160 - val_loss: 0.1284 - 3s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "161/161 - 3s - loss: 0.1113 - val_loss: 0.1188 - 3s/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "161/161 - 3s - loss: 0.1071 - val_loss: 0.1171 - 3s/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "161/161 - 3s - loss: 0.1037 - val_loss: 0.1166 - 3s/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "161/161 - 3s - loss: 0.1009 - val_loss: 0.1160 - 3s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "161/161 - 3s - loss: 0.0977 - val_loss: 0.1137 - 3s/epoch - 18ms/step\n",
      "Epoch 16/100\n",
      "161/161 - 3s - loss: 0.0957 - val_loss: 0.1173 - 3s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "161/161 - 3s - loss: 0.0931 - val_loss: 0.1149 - 3s/epoch - 16ms/step\n",
      "Epoch 17: early stopping\n",
      "41/41 [==============================] - 0s 4ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 2s - loss: 0.8937 - val_loss: 0.5421 - 2s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 1s - loss: 0.5398 - val_loss: 0.5433 - 535ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 1s - loss: 0.5415 - val_loss: 0.5364 - 569ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 1s - loss: 0.5410 - val_loss: 0.5405 - 517ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 1s - loss: 0.5396 - val_loss: 0.5408 - 502ms/epoch - 3ms/step\n",
      "Epoch 5: early stopping\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 10s - loss: 0.7762 - val_loss: 0.5134 - 10s/epoch - 59ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 8s - loss: 0.2487 - val_loss: 0.3751 - 8s/epoch - 51ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 8s - loss: 0.1363 - val_loss: 0.1309 - 8s/epoch - 50ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 8s - loss: 0.1139 - val_loss: 0.1718 - 8s/epoch - 50ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 8s - loss: 0.1028 - val_loss: 0.1452 - 8s/epoch - 49ms/step\n",
      "Epoch 5: early stopping\n",
      "41/41 [==============================] - 1s 10ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 10s - loss: 0.8500 - val_loss: 0.5391 - 10s/epoch - 60ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 8s - loss: 0.5424 - val_loss: 0.5366 - 8s/epoch - 49ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 8s - loss: 0.5403 - val_loss: 0.5161 - 8s/epoch - 48ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 8s - loss: 0.4955 - val_loss: 0.2184 - 8s/epoch - 50ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 8s - loss: 0.1944 - val_loss: 0.2059 - 8s/epoch - 50ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 8s - loss: 0.1294 - val_loss: 0.1118 - 8s/epoch - 50ms/step\n",
      "Epoch 7/100\n",
      "161/161 - 8s - loss: 0.1061 - val_loss: 0.1116 - 8s/epoch - 49ms/step\n",
      "Epoch 8/100\n",
      "161/161 - 8s - loss: 0.0992 - val_loss: 0.1096 - 8s/epoch - 51ms/step\n",
      "Epoch 9/100\n",
      "161/161 - 8s - loss: 0.0903 - val_loss: 0.1190 - 8s/epoch - 48ms/step\n",
      "Epoch 10/100\n",
      "161/161 - 8s - loss: 0.0848 - val_loss: 0.2597 - 8s/epoch - 48ms/step\n",
      "Epoch 10: early stopping\n",
      "41/41 [==============================] - 1s 9ms/step\n",
      "Epoch 1/100\n",
      "161/161 - 13s - loss: 0.8210 - val_loss: 0.4687 - 13s/epoch - 82ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 11s - loss: 0.2180 - val_loss: 0.1389 - 11s/epoch - 68ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 11s - loss: 0.1257 - val_loss: 0.1692 - 11s/epoch - 67ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 11s - loss: 0.1082 - val_loss: 0.1413 - 11s/epoch - 69ms/step\n",
      "Epoch 4: early stopping\n",
      "41/41 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "model_results = []\n",
    "\n",
    "for model in model_types:\n",
    "    hidden_layer = model['hidden_layers']\n",
    "    activation_function = model['activation_function']\n",
    "    optimizer = model['optimizer']\n",
    "    dropout_rate = model['dropout_rate']\n",
    "    learning_rate = model['learning_rate']\n",
    "    batch_size = model['batch_size']\n",
    "    \n",
    "    results = model_tester(\n",
    "        hidden_layers=hidden_layer, \n",
    "        learning_rate=learning_rate, \n",
    "        optimizer=optimizer,\n",
    "        activation_function=activation_function, \n",
    "        dropout_rate=dropout_rate, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    model_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>pred</th>\n",
       "      <th>rmse</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>i</td>\n",
       "      <td>h</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>r</td>\n",
       "      <td>d</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>r</td>\n",
       "      <td>p</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>m</td>\n",
       "      <td>r</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>e</td>\n",
       "      <td>l</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.0852208], [4.3812695], [3.7488027], [3.984...</td>\n",
       "      <td>0.337063</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.7501323], [4.538156], [3.6912217], [4.0042...</td>\n",
       "      <td>0.340174</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.6016736], [3.6012163], [3.6017456], [3.601...</td>\n",
       "      <td>0.732526</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.978917], [4.699371], [3.877561], [4.025325...</td>\n",
       "      <td>0.34888</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[3.0493488], [4.4737854], [3.9084039], [3.895...</td>\n",
       "      <td>0.371367</td>\n",
       "      <td>0.010</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.8643498], [4.4003954], [3.8360026], [3.955...</td>\n",
       "      <td>0.33399</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1024, 512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.6681638], [4.2512536], [3.6541724], [3.869...</td>\n",
       "      <td>0.359348</td>\n",
       "      <td>0.010</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1024, 512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.789482], [4.593974], [3.9033968], [4.00183...</td>\n",
       "      <td>0.345298</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1024, 512, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.8222718], [4.494869], [3.8134341], [3.9945...</td>\n",
       "      <td>0.337187</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[160, 80, 40, 20, 10, 5]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[3.5617006], [3.5615058], [3.561439], [3.5614...</td>\n",
       "      <td>0.732406</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1024, 2048, 1024, 512, 1024, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.6309934], [4.265285], [3.8108473], [3.8037...</td>\n",
       "      <td>0.361833</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1024, 2048, 516, 256, 128, 2048, 128, 256, 51...</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[2.7801218], [4.4380503], [3.7757123], [4.059...</td>\n",
       "      <td>0.330986</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[4096, 1024, 256, 128, 64, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[[3.0341587], [4.4111657], [3.9995878], [4.019...</td>\n",
       "      <td>0.372757</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        hidden_layers activation_function  \\\n",
       "0                                      [256, 128, 64]                relu   \n",
       "1                                      [256, 128, 64]             sigmoid   \n",
       "2                                      [256, 128, 64]                tanh   \n",
       "3                                      [256, 128, 64]                relu   \n",
       "4                                      [256, 128, 64]             sigmoid   \n",
       "5                                      [256, 128, 64]                tanh   \n",
       "6                                 [512, 256, 128, 64]                relu   \n",
       "7                                 [512, 256, 128, 64]             sigmoid   \n",
       "8                                 [512, 256, 128, 64]                tanh   \n",
       "9                                 [512, 256, 128, 64]                relu   \n",
       "10                                [512, 256, 128, 64]             sigmoid   \n",
       "11                                [512, 256, 128, 64]                tanh   \n",
       "12                                    [512, 256, 128]                relu   \n",
       "13                                    [512, 256, 128]                relu   \n",
       "14                              [1024, 512, 256, 128]                relu   \n",
       "15                              [1024, 512, 256, 128]                relu   \n",
       "16                              [1024, 512, 256, 128]                relu   \n",
       "17                           [160, 80, 40, 20, 10, 5]                relu   \n",
       "18            [1024, 2048, 1024, 512, 1024, 256, 128]                relu   \n",
       "19  [1024, 2048, 516, 256, 128, 2048, 128, 256, 51...                relu   \n",
       "20                     [4096, 1024, 256, 128, 64, 32]                relu   \n",
       "\n",
       "   optimizer  dropout_rate                                               pred  \\\n",
       "0       adam           0.2                                                  i   \n",
       "1       adam           0.2                                                  c   \n",
       "2       adam           0.2                                                  p   \n",
       "3        sgd           0.2                                                  r   \n",
       "4        sgd           0.2                                                  r   \n",
       "5        sgd           0.2                                                  m   \n",
       "6       adam           0.2                                                  e   \n",
       "7       adam           0.2                                                  a   \n",
       "8       adam           0.2  [[3.0852208], [4.3812695], [3.7488027], [3.984...   \n",
       "9        sgd           0.2  [[2.7501323], [4.538156], [3.6912217], [4.0042...   \n",
       "10       sgd           0.2  [[3.6016736], [3.6012163], [3.6017456], [3.601...   \n",
       "11       sgd           0.2  [[2.978917], [4.699371], [3.877561], [4.025325...   \n",
       "12       sgd           0.2  [[3.0493488], [4.4737854], [3.9084039], [3.895...   \n",
       "13       sgd           0.2  [[2.8643498], [4.4003954], [3.8360026], [3.955...   \n",
       "14       sgd           0.2  [[2.6681638], [4.2512536], [3.6541724], [3.869...   \n",
       "15       sgd           0.2  [[2.789482], [4.593974], [3.9033968], [4.00183...   \n",
       "16       sgd           0.2  [[2.8222718], [4.494869], [3.8134341], [3.9945...   \n",
       "17       sgd           0.1  [[3.5617006], [3.5615058], [3.561439], [3.5614...   \n",
       "18       sgd           0.2  [[2.6309934], [4.265285], [3.8108473], [3.8037...   \n",
       "19       sgd           0.2  [[2.7801218], [4.4380503], [3.7757123], [4.059...   \n",
       "20       sgd           0.4  [[3.0341587], [4.4111657], [3.9995878], [4.019...   \n",
       "\n",
       "        rmse  learning_rate  batch_size  \n",
       "0          h          0.010          32  \n",
       "1          a          0.010          32  \n",
       "2          o          0.010          32  \n",
       "3          d          0.010          32  \n",
       "4          p          0.010          32  \n",
       "5          r          0.010          32  \n",
       "6          l          0.001          32  \n",
       "7          b          0.001          32  \n",
       "8   0.337063          0.001          32  \n",
       "9   0.340174          0.001          32  \n",
       "10  0.732526          0.001          32  \n",
       "11   0.34888          0.001          32  \n",
       "12  0.371367          0.010          16  \n",
       "13   0.33399          0.010          32  \n",
       "14  0.359348          0.010          16  \n",
       "15  0.345298          0.001          16  \n",
       "16  0.337187          0.001          32  \n",
       "17  0.732406          0.010          32  \n",
       "18  0.361833          0.010          32  \n",
       "19  0.330986          0.010          32  \n",
       "20  0.372757          0.010          32  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model types with model_results\n",
    "for i, result in enumerate(model_results):\n",
    "    model_types[i]['rmse'] = result[0]\n",
    "    model_types[i]['pred'] = result[1]  \n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "model_results = pd.DataFrame(model_types)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 0.3309861719608307\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business name: St Honore Pastries, Rating: 4.5, Predicted Rating: [2.7801218]\n",
      "2. Business name: Denny's, Rating: 4.5, Predicted Rating: [4.4380503]\n",
      "3. Business name: Zio's Italian Market, Rating: 4.5, Predicted Rating: [3.7757123]\n",
      "4. Business name: Tuna Bar, Rating: 4.0, Predicted Rating: [4.0593734]\n",
      "5. Business name: BAP, Rating: 3.5, Predicted Rating: [3.0042734]\n"
     ]
    }
   ],
   "source": [
    "# Get best model results\n",
    "rmse = model_results['rmse'][19]\n",
    "pred = model_results['pred'][19]\n",
    "\n",
    "print(\"Score (RMSE): {}\".format(rmse))\n",
    "chart_regression(pred.flatten(),y_test)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"{}. Business name: {}, Rating: {}, Predicted Rating: {}\".format(i+1,business.iloc[i]['name'],y[i],pred[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
